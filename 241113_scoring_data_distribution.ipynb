{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBJWAQhwbfJUK3yX7xxs3Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuchenhe-xai/yccolab/blob/main/241113_scoring_data_distribution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scores for data learnability\n",
        "As discussed in [doc](https://docs.google.com/document/d/1msVlIjZwDUNpwalNuJ60P-9ieSINEVsC5ItyIBPUHPk/edit?tab=t.0#heading=h.y24asf17gdl1) - we want to find the data distributions that worth labeling and RL against. Besides matching the distribution based on clustering and categories, here we are defining a score approximating the learnability. Our assumption is that examples with higher score is more learnable - aka policy would differs before and after training - model could learn from it.\n",
        "\n",
        "Here are 3 different options, note ${a}$ is the LLM token output, $p = p_\\text{target}(a|s)$ is the target policy after RL, $q = p_\\text{ref}(a|s)$ is the original SFT policy.\n",
        "- importance weight (similar as in ppo's off-policy importance weight) : $s = p/q$\n",
        "- cross entropy: $s = - p \\log q$\n",
        "- kl divergence: $s = p \\log (p/q)$\n",
        "\n",
        "Here we wrap this into a reward client to be used downstream."
      ],
      "metadata": {
        "id": "kcwvYJgR3Exa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title imports\n",
        "\n",
        "import aiohttp\n",
        "import asyncio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "from enum import Enum\n",
        "from tqdm import tqdm\n",
        "from typing import Any\n",
        "from xlm.config import Config\n",
        "from xlm.config import configclass\n",
        "from xlm.posttrain import utils\n",
        "from xlm.posttrain.data import formatting\n",
        "from xlm.sampling_client import SamplingClient\n",
        "from xlm.tokenizers.constants import get_tokenizer, Tokenizer\n"
      ],
      "metadata": {
        "id": "y0rld9kB-h6w"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3qyQIn328Z5",
        "outputId": "ebc51caf-edd2-485e-a542-074c2896d96f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score_type': 'KL',\n",
              " 'gap_score': 0.00020714638402634904,\n",
              " 'target_score': 0.0002712848156840789,\n",
              " 'ref_score': 6.419461970451348e-05}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#@title define scorer\n",
        "DEFAULT_TOKENIZER = get_tokenizer(\"v4\")\n",
        "SFT_MODEL = \"v5l-1010-sft-rubrics-sglang.yuchen.svc.max.x.ai\"\n",
        "POLICY_MODEL = \"v5l-inf-mb-sglang.yuchen.svc.max.x.ai\"\n",
        "\n",
        "class ScoreType(Enum):\n",
        "  P = 0\n",
        "  CE = 1\n",
        "  KL = 2\n",
        "\n",
        "@configclass\n",
        "class RelativeScorer(Config):\n",
        "  tokenizer: Tokenizer = DEFAULT_TOKENIZER\n",
        "  timeout: int = 100\n",
        "  model_addr: str = POLICY_MODEL\n",
        "  model_addr_ref: str = SFT_MODEL\n",
        "  score_type : ScoreType = ScoreType.KL\n",
        "  max_parallel: int = 1024\n",
        "  semaphore = asyncio.Semaphore(value=max_parallel)\n",
        "\n",
        "  async def get_logprob(self, prompt: str, response: str, model_addr: str = None) -> float:\n",
        "      \"\"\"Compute the log probabilities for response\"\"\"\n",
        "      prompt_tokens = self.tokenizer.tokenize_no_eos(prompt)\n",
        "      suffix_prob = np.inf\n",
        "      async with self.semaphore:\n",
        "        async with aiohttp.ClientSession(\n",
        "            timeout=aiohttp.ClientTimeout(total=self.timeout)\n",
        "        ) as session:\n",
        "          logp_response = await session.post(\n",
        "              f\"http://{model_addr}:30000/generate\",\n",
        "              json={\n",
        "                  \"text\": prompt + response,\n",
        "                  \"sampling_params\": {\"temperature\": 0, \"max_new_tokens\": 0},\n",
        "                  \"return_logprob\": True,\n",
        "                  \"logprob_start_len\": len(prompt_tokens) - 1,\n",
        "              },\n",
        "          )\n",
        "          response_json = await logp_response.json()\n",
        "          suffix_logprobs = response_json[\"meta_info\"][\"input_token_logprobs\"]\n",
        "          logprobs = [ri[0] for ri in suffix_logprobs]\n",
        "          suffix_prob = np.exp(np.mean(logprobs)).item()\n",
        "      return suffix_prob\n",
        "\n",
        "  async def get_scores(self, prompt: str, response: str):\n",
        "      target_score = await self.get_logprob(prompt, response, model_addr=self.model_addr)\n",
        "      ref_score = await self.get_logprob(prompt, response, model_addr=self.model_addr_ref)\n",
        "      gap_score = None\n",
        "      match self.score_type :\n",
        "        case ScoreType.P:\n",
        "          gap_score = np.exp(target_score - ref_score)\n",
        "        case ScoreType.CE:\n",
        "          gap_score =  - target_score * np.exp(ref_score)\n",
        "        case ScoreType.KL:\n",
        "          gap_score = np.exp(target_score) * (target_score - ref_score)\n",
        "      scores = {\"score_type\": self.score_type.name, \"gap_score\": gap_score, \"target_score\": target_score, \"ref_score\": ref_score}\n",
        "      # we cares larger gap - more negative the more learning\n",
        "      return scores\n",
        "\n",
        "scorer = RelativeScorer()\n",
        "await scorer.get_scores(prompt=\"asdfs\", response=\"dx\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title a new reward client that does scoring\n",
        "from xlm.reward_client import RewardClient\n",
        "from dataclasses import field\n",
        "\n",
        "@configclass\n",
        "class RelativeRewardClient(RewardClient):\n",
        "    model_addr: str = POLICY_MODEL\n",
        "    model_addr_ref: str = SFT_MODEL\n",
        "    score_type: ScoreType = ScoreType.KL\n",
        "    scorer: RelativeScorer = None\n",
        "\n",
        "    def __post_init__(self):\n",
        "\n",
        "        # if response is not provided or we want to use a specific model response, we set up the sampling client for it\n",
        "        if self.address.endswith(\"/\"):\n",
        "          self.address = self.address[:-1]\n",
        "        self.sampling_client = SamplingClient()\n",
        "        self.model = self.address.split(\"/\")[0]\n",
        "        self.sampling_client._grok_client.register_model(\n",
        "           model=self.model, model_address=self.address, max_parallel=self.max_parallel\n",
        "        )\n",
        "        self.semaphore = asyncio.Semaphore(value=self.max_parallel)\n",
        "        if self.scorer is None:\n",
        "          self.scorer = RelativeScorer(\n",
        "              model_addr=self.model_addr, model_addr_ref=self.model_addr_ref, score_type=self.score_type\n",
        "          )\n",
        "\n",
        "\n",
        "    async def _generate(\n",
        "        self, messages: list[dict[str, str]] = None, example: dict[str, Any] = None\n",
        "    ) -> dict[str, Any]:\n",
        "        try:\n",
        "          async with self.semaphore:\n",
        "            prompt = example.get(\"prompt\", None)\n",
        "            response = example.get(\"response\", None)\n",
        "            if messages is not None:\n",
        "              if messages[-1][\"role\"] in [\"ASSIS\", \"assistant\"]:\n",
        "                  prompt = formatting.render_conversation(\n",
        "                      name=\"grok\", messages=messages[:-1]\n",
        "                  )\n",
        "                  response = messages[-1][\"content\"]\n",
        "              else:\n",
        "                  prompt = formatting.render_conversation(\n",
        "                      name=\"grok\", messages=messages\n",
        "                  )\n",
        "            if response is None:\n",
        "              response = await self.sampling_client.generate(prompt=prompt)\n",
        "            scores = await self.scorer.get_scores(prompt=prompt, response=response)\n",
        "            example[\"scores\"] = scores\n",
        "            return scores\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            traceback.print_exc()\n",
        "            return None\n",
        "\n"
      ],
      "metadata": {
        "id": "tQv9deQ164rP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Human: You will classify what genre each book is based on its summary.  When answering give both the genre name and a short (1-2 sentences) justification for why it is that genre.  If a book could be classified as multiple genres pick the one that fits the best. Here are the genres:\n",
        "\n",
        "[Fantasy]: A genre of imaginative fiction involving magic and adventure, especially in a setting other than the real world\n",
        "[Science Fiction]: A form of fiction that deals principally with the impact of actual or imagined science upon society or individuals.\n",
        "[Dystopian]: A popular genre of science fiction, dystopian novels offer a bleak and frightening vision of the future.\n",
        "[Action & Adventure]: The protagonist has a very important goal to achieve, but they’re going to have to go through the wringer first! The hero experiences obstacle after obstacle and goes through downright dangerous situations but eventually, they triumph and return home transformed.\n",
        "[Mystery]: Also called detective fiction, this book genre is characterized by a gripping plot that revolves around a mystery.\n",
        " [Historical Fiction]: This book genre encompasses fictional stories in a historical setting, carefully balancing creativity and facts. In most cases, the characters and events are imagined by the author and enriched with historically accurate details from a specific time period.\n",
        "[Romance]:  The key thing to remember is that the romantic relationship must be the center point of the plot. (Other giveaways include a “happily ever after” ending and the warm fuzzies.)\n",
        "[Contemporary Fiction]: This book genre is occasionally lumped in with others to indicate that the book takes place in the present day. But in its simplest form, contemporary fiction is better understood as the absence of a genre. Your book doesn’t need tropes and trappings, monsters and mysteries, when its tension, drama, and conflict lies in the quirks and quandaries of your protagonist’s everyday life: work, politics, relationships, and the struggles of the modern era.\n",
        "[Literary Fiction]: Like contemporary fiction, books considered literary fiction can’t be neatly filed under any other genre. What distinguishes this genre from contemporary fiction is that works of literary fiction are thought to have considerable artistic value. If your prose is meant to engage the reader in thought, if your narrative is character-driven and introspective, and if you provide personal or social commentary on a “serious” theme, then chances are you’re writing lit-fic\n",
        "\n",
        "Your output should consist of the name of the genre in bold followed by the 1-2 sentence justification for why the book is considered to be that genre.\n",
        "\n",
        "Classify this book based on the summary:\n",
        "\n",
        "Crown of Secrets by Melanie Cellier\n",
        "Verene is a disappointment to her entire kingdom--the first royal ever born without power, despite her mother being the most powerful mage in history. So when she's sent to the Academy in neighboring Kallorway to forge ties with her people's traditional enemies, she's determined to succeed and prove she can still be of value to her kingdom.\n",
        "\n",
        "Prince Darius of Kallorway is the strongest mage in his family--and the only reason his weak father is still clinging to his throne. Starting at the Academy at the same time as Verene, the crown prince is cold and distant and shows no desire to connect with her. Instead he seems suspicious of both her presence and her claimed lack of power.\n",
        "\n",
        "Surrounded by unfamiliar politics and long-held enemies, Verene discovers that some at the Academy want her gone by whatever means necessary. As the threats grow ever more sinister, she starts to question all of her assumptions. The hardened prince might just be her best hope of survival and--even more shockingly--he might be right about her power. If Verene wants to survive Kallorway and the Academy, she must uncover her hidden powers and take her true place among the mages.<|separator|>\n",
        "\n",
        "Assistant:\"\"\".strip()\n",
        "response = \"This book is classified as fantasy because it involves a world with magic and mages, which is a classic element of fantasy settings, and the plot revolves around magical powers and political intrigue in an imagined kingdom.\"\n",
        "example = {\"prompt\": prompt, \"response\": response}\n",
        "\n",
        "rr = RelativeRewardClient(address=\"v5l-1101-crm.yuchen.svc.max.x.ai\")\n",
        "await rr._generate(example=example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLayEhGvAVve",
        "outputId": "e4ef0835-188b-4ded-e990-c1e1d729d82c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m[2024-11-14 19:44:01,123 E] \u001b[2;36m[colabbox-0:1619717] sampling_client:1010:\u001b[0m bedrock setup failed: The config profile (key0) could not be found\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score_type': 'KL',\n",
              " 'gap_score': 0.026509963720824595,\n",
              " 'target_score': 0.1790255514643105,\n",
              " 'ref_score': 0.1568609807490007}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title example of wrapping the scoring into a data processing pipeline\n",
        "\n",
        "\n",
        "# for new policy answer - if we dont have a model generated response yet\n",
        "DEFAULT_MODEL = \"v5l-1101-crm.yuchen.svc.max.x.ai\"\n",
        "\n",
        "sampling_client = SamplingClient()\n",
        "sampling_client._grok_client.register_model(\n",
        "    model=DEFAULT_MODEL, model_address=DEFAULT_MODEL\n",
        ")\n",
        "scorer = RelativeScorer()\n",
        "\n",
        "async def process_convo(\n",
        "    input_path, output_path, sampling_client = None, semaphore = None, pbar=None, scorer: RelativeScorer = scorer\n",
        "):\n",
        "    df1 = utils.read_df(glob.glob(input_path))\n",
        "    row_pbar = tqdm(total=len(df1), desc=f\"Processing {input_path}\", leave=False)\n",
        "    async def process_row(example):\n",
        "        example = example.to_dict() if not isinstance(example, dict) else example\n",
        "        reward = None\n",
        "        conv = example.get('conversation0')[:-1]\n",
        "        prompt = formatting.render_conversation(name=\"grok\", messages=conv) if conv is not None else None\n",
        "        if sampling_client:\n",
        "          response = sampling_client.generate(prompt=prompt)\n",
        "        else:\n",
        "          model_id_0 = example.get(\"model_0_id\")\n",
        "          model_id_1 =  example.get(\"model_1_id\")\n",
        "          if \"grok\" in model_id_0 and \"grok\" in model_id_1:\n",
        "            chosen_model = 0 if example.get(\"model_0_id\") > example.get(\"model_1_id\") else 1\n",
        "          elif \"grok\" in model_id_0:\n",
        "            chosen_model = 0\n",
        "          elif \"grok\" in model_id_1:\n",
        "            chosen_model = 1\n",
        "          else:\n",
        "            chosen_model = 0\n",
        "          response = example.get(f'conversation{chosen_model}', [])[-1][\"content\"]\n",
        "        scores = await scorer.get_scores(prompt, response)\n",
        "        example.update({\"entropy_scores\": scores})\n",
        "        row_pbar.update(1)\n",
        "        return example\n",
        "    # Process in batches\n",
        "    batch_size = 10_000  # len(df1) #  1000  # Adjust this based on your system's capacity\n",
        "    mapped_data = []\n",
        "    for start in range(0, len(df1), batch_size):\n",
        "        batch = df1.iloc[start : start + batch_size]\n",
        "        batch_results = await asyncio.gather(\n",
        "            *(process_row(example) for _, example in batch.iterrows())\n",
        "        )\n",
        "        mapped_data.extend(batch_results)\n",
        "\n",
        "    df2 = pd.DataFrame(mapped_data)\n",
        "    def getentropygap(row):\n",
        "        return row['entropy_scores']['gap_score']\n",
        "\n",
        "    # Apply the function to create a new column or use directly for sorting\n",
        "    # Here, we create a temporary column for clarity, but you can also sort directly\n",
        "    df2['temp_entropy_gap'] = df2.apply(getentropygap, axis=1)\n",
        "\n",
        "    # Now sort the DataFrame by the temporary column\n",
        "    df2_sorted = df2.sort_values(by='temp_entropy_gap', ascending=True)\n",
        "\n",
        "    utils.df_to_parquet(df2_sorted, output_path)\n",
        "    return df2_sorted\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m91yKZlx3Ilm",
        "outputId": "16136c46-6b91-4fb8-b0a2-a1d0de22b431"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m[2024-11-14 19:44:02,407 E] \u001b[2;36m[colabbox-0:1619717] sampling_client:1010:\u001b[0m bedrock setup failed: The config profile (key0) could not be found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_folder = \"/data/datasets/preferences-v2/filtered/xrenewNONE/train/surge_api_1/data/*.parquet\"\n",
        "output_path = \"/data/datasets/preferences-v2/filtered/xrenewNONEentropy/surge_api_1/\"\n",
        "newdata = await process_convo(input_folder, output_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHh0lEOR6ejf",
        "outputId": "874e1664-91fc-47ef-de74-c9105cd408db"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "reading paths: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 33.97it/s]\n",
            "Processing /data/datasets/preferences-v2/filtered/xrenewNONE/train/surge_api_1/data/*.parquet:  99%|████████████████████████████▊| 756/762 [01:05<00:00, 17.03it/s]\n",
            "storing df as parquets:   0%|                                                                                                                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "storing df as parquets: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.20it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newdata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 979
        },
        "id": "RC3uL6aP6nYt",
        "outputId": "2e1237a7-1f12-4bd5-d6ae-1ed64ee4de09"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         id          domain  \\\n",
              "721  6c56a226-dbf9-46f9-98ed-658813ea2d8f:4  Classification   \n",
              "17   3927efbf-3735-4c93-96fc-2782deec5e9e:1      Extraction   \n",
              "398  3927efbf-3735-4c93-96fc-2782deec5e9e:1      Extraction   \n",
              "340  6c56a226-dbf9-46f9-98ed-658813ea2d8f:4  Classification   \n",
              "363  5be95b0c-e19d-4add-8557-a2f276394522:1  Classification   \n",
              "..                                      ...             ...   \n",
              "756  655a9956-a9c5-4dc5-a253-63dbd8d9d750:3           Other   \n",
              "33   b70550a3-fe2c-4ebe-b604-71192a2ff040:2           Other   \n",
              "414  b70550a3-fe2c-4ebe-b604-71192a2ff040:2           Other   \n",
              "364  5be95b0c-e19d-4add-8557-a2f276394522:3  Classification   \n",
              "754  0d45a2b9-5de5-4d0d-8a31-2be88955a298:1  Classification   \n",
              "\n",
              "                                                critic  \\\n",
              "721  Both models made errors in classifying the job...   \n",
              "17   Model A had incorrect formatting of the CSV ta...   \n",
              "398  Model A had incorrect formatting of the CSV ta...   \n",
              "340  Both models made errors in classifying the job...   \n",
              "363  Both models followed the instructions verbatim...   \n",
              "..                                                 ...   \n",
              "756  Both of these responses would be appropriate g...   \n",
              "33   Both models accurately calculated the smallest...   \n",
              "414  Both models accurately calculated the smallest...   \n",
              "364  Both models responded with modified classifica...   \n",
              "754  Both models followed the instructions given. E...   \n",
              "\n",
              "                                          conversation  \\\n",
              "721  [{'content': 'You are an intelligent assistant...   \n",
              "17   [{'content': 'You will extract information fro...   \n",
              "398  [{'content': 'You will extract information fro...   \n",
              "340  [{'content': 'You are an intelligent assistant...   \n",
              "363  [{'content': 'Analyse a series of blurbs about...   \n",
              "..                                                 ...   \n",
              "756  [{'content': 'You are a model that is designed...   \n",
              "33   [{'content': 'Convert the input recipes to the...   \n",
              "414  [{'content': 'Convert the input recipes to the...   \n",
              "364  [{'content': 'Analyse a series of blurbs about...   \n",
              "754  [{'content': 'I'm trying to figure out when I ...   \n",
              "\n",
              "                                        conv_loss_mask  \\\n",
              "721  [False, False, False, False, False, False, Fal...   \n",
              "17   [False, False, False, True, False, False, Fals...   \n",
              "398  [False, False, False, True, False, False, Fals...   \n",
              "340  [False, False, False, False, False, False, Fal...   \n",
              "363  [False, False, False, True, False, False, Fals...   \n",
              "..                                                 ...   \n",
              "756  [False, False, False, False, False, False, Fal...   \n",
              "33   [False, False, False, False, False, True, Fals...   \n",
              "414  [False, False, False, False, False, True, Fals...   \n",
              "364  [False, False, False, False, False, False, Fal...   \n",
              "754  [False, False, False, True, False, False, Fals...   \n",
              "\n",
              "                                         conversation0  \\\n",
              "721  [{'content': 'You are an intelligent assistant...   \n",
              "17   [{'content': 'You will extract information fro...   \n",
              "398  [{'content': 'You will extract information fro...   \n",
              "340  [{'content': 'You are an intelligent assistant...   \n",
              "363  [{'content': 'Analyse a series of blurbs about...   \n",
              "..                                                 ...   \n",
              "756  [{'content': 'You are a model that is designed...   \n",
              "33   [{'content': 'Convert the input recipes to the...   \n",
              "414  [{'content': 'Convert the input recipes to the...   \n",
              "364  [{'content': 'Analyse a series of blurbs about...   \n",
              "754  [{'content': 'I'm trying to figure out when I ...   \n",
              "\n",
              "                                         conversation1  preference_overall  \\\n",
              "721  [{'content': 'You are an intelligent assistant...                 0.0   \n",
              "17   [{'content': 'You will extract information fro...                 1.0   \n",
              "398  [{'content': 'You will extract information fro...                 1.0   \n",
              "340  [{'content': 'You are an intelligent assistant...                 0.0   \n",
              "363  [{'content': 'Analyse a series of blurbs about...                 1.0   \n",
              "..                                                 ...                 ...   \n",
              "756  [{'content': 'You are a model that is designed...                 0.0   \n",
              "33   [{'content': 'Convert the input recipes to the...                 0.0   \n",
              "414  [{'content': 'Convert the input recipes to the...                 0.0   \n",
              "364  [{'content': 'Analyse a series of blurbs about...                 1.0   \n",
              "754  [{'content': 'I'm trying to figure out when I ...                 1.0   \n",
              "\n",
              "                      model_0_id                   model_1_id  ...  \\\n",
              "721  grok-0701-2.research-models  grok-0805-1.research-models  ...   \n",
              "17   grok-0701-2.research-models  grok-0805-1.research-models  ...   \n",
              "398  grok-0701-2.research-models  grok-0805-1.research-models  ...   \n",
              "340  grok-0701-2.research-models  grok-0805-1.research-models  ...   \n",
              "363  grok-0701-2.research-models  grok-0805-1.research-models  ...   \n",
              "..                           ...                          ...  ...   \n",
              "756  grok-0701-2.research-models  grok-0805-1.research-models  ...   \n",
              "33   grok-0701-2.research-models  grok-0805-1.research-models  ...   \n",
              "414  grok-0701-2.research-models  grok-0805-1.research-models  ...   \n",
              "364  grok-0701-2.research-models  grok-0805-1.research-models  ...   \n",
              "754  grok-0701-2.research-models  grok-0805-1.research-models  ...   \n",
              "\n",
              "    reward_aspects_details_B reward_aspects_ratings_B reward_truth_A  \\\n",
              "721                                                                5   \n",
              "17                                                                 1   \n",
              "398                                                                1   \n",
              "340                                                                5   \n",
              "363                                                                1   \n",
              "..                       ...                      ...            ...   \n",
              "756                                                                5   \n",
              "33                                                                 5   \n",
              "414                                                                5   \n",
              "364                                                                1   \n",
              "754                                                                1   \n",
              "\n",
              "    reward_truth_B ideal_response  rubrics  \\\n",
              "721              1                           \n",
              "17               5                           \n",
              "398              5                           \n",
              "340              1                           \n",
              "363              5                           \n",
              "..             ...            ...      ...   \n",
              "756              1                           \n",
              "33               1                           \n",
              "414              1                           \n",
              "364              5                           \n",
              "754              5                           \n",
              "\n",
              "                                                 data0  \\\n",
              "721  Human: You are an intelligent assistant advisi...   \n",
              "17   Human: You will extract information from the f...   \n",
              "398  Human: You will extract information from the f...   \n",
              "340  Human: You are an intelligent assistant advisi...   \n",
              "363  Human: Analyse a series of blurbs about guitar...   \n",
              "..                                                 ...   \n",
              "756  Human: You are a model that is designed to hel...   \n",
              "33   Human: Convert the input recipes to their smal...   \n",
              "414  Human: Convert the input recipes to their smal...   \n",
              "364  Human: Analyse a series of blurbs about guitar...   \n",
              "754  Human: I'm trying to figure out when I can kee...   \n",
              "\n",
              "                                                 data1  \\\n",
              "721  Human: You are an intelligent assistant advisi...   \n",
              "17   Human: You will extract information from the f...   \n",
              "398  Human: You will extract information from the f...   \n",
              "340  Human: You are an intelligent assistant advisi...   \n",
              "363  Human: Analyse a series of blurbs about guitar...   \n",
              "..                                                 ...   \n",
              "756  Human: You are a model that is designed to hel...   \n",
              "33   Human: Convert the input recipes to their smal...   \n",
              "414  Human: Convert the input recipes to their smal...   \n",
              "364  Human: Analyse a series of blurbs about guitar...   \n",
              "754  Human: I'm trying to figure out when I can kee...   \n",
              "\n",
              "                                        entropy_scores temp_entropy_gap  \n",
              "721  {'score_type': 'KL', 'gap_score': -0.108779391...        -0.108779  \n",
              "17   {'score_type': 'KL', 'gap_score': -0.106064621...        -0.106065  \n",
              "398  {'score_type': 'KL', 'gap_score': -0.105023694...        -0.105024  \n",
              "340  {'score_type': 'KL', 'gap_score': -0.100402321...        -0.100402  \n",
              "363  {'score_type': 'KL', 'gap_score': -0.093293909...        -0.093294  \n",
              "..                                                 ...              ...  \n",
              "756  {'score_type': 'KL', 'gap_score': 0.0813806601...         0.081381  \n",
              "33   {'score_type': 'KL', 'gap_score': 0.0828912649...         0.082891  \n",
              "414  {'score_type': 'KL', 'gap_score': 0.0852000482...         0.085200  \n",
              "364  {'score_type': 'KL', 'gap_score': 0.0911822683...         0.091182  \n",
              "754  {'score_type': 'KL', 'gap_score': 0.1026359613...         0.102636  \n",
              "\n",
              "[762 rows x 23 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>domain</th>\n",
              "      <th>critic</th>\n",
              "      <th>conversation</th>\n",
              "      <th>conv_loss_mask</th>\n",
              "      <th>conversation0</th>\n",
              "      <th>conversation1</th>\n",
              "      <th>preference_overall</th>\n",
              "      <th>model_0_id</th>\n",
              "      <th>model_1_id</th>\n",
              "      <th>...</th>\n",
              "      <th>reward_aspects_details_B</th>\n",
              "      <th>reward_aspects_ratings_B</th>\n",
              "      <th>reward_truth_A</th>\n",
              "      <th>reward_truth_B</th>\n",
              "      <th>ideal_response</th>\n",
              "      <th>rubrics</th>\n",
              "      <th>data0</th>\n",
              "      <th>data1</th>\n",
              "      <th>entropy_scores</th>\n",
              "      <th>temp_entropy_gap</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>721</th>\n",
              "      <td>6c56a226-dbf9-46f9-98ed-658813ea2d8f:4</td>\n",
              "      <td>Classification</td>\n",
              "      <td>Both models made errors in classifying the job...</td>\n",
              "      <td>[{'content': 'You are an intelligent assistant...</td>\n",
              "      <td>[False, False, False, False, False, False, Fal...</td>\n",
              "      <td>[{'content': 'You are an intelligent assistant...</td>\n",
              "      <td>[{'content': 'You are an intelligent assistant...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>grok-0701-2.research-models</td>\n",
              "      <td>grok-0805-1.research-models</td>\n",
              "      <td>...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Human: You are an intelligent assistant advisi...</td>\n",
              "      <td>Human: You are an intelligent assistant advisi...</td>\n",
              "      <td>{'score_type': 'KL', 'gap_score': -0.108779391...</td>\n",
              "      <td>-0.108779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>3927efbf-3735-4c93-96fc-2782deec5e9e:1</td>\n",
              "      <td>Extraction</td>\n",
              "      <td>Model A had incorrect formatting of the CSV ta...</td>\n",
              "      <td>[{'content': 'You will extract information fro...</td>\n",
              "      <td>[False, False, False, True, False, False, Fals...</td>\n",
              "      <td>[{'content': 'You will extract information fro...</td>\n",
              "      <td>[{'content': 'You will extract information fro...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>grok-0701-2.research-models</td>\n",
              "      <td>grok-0805-1.research-models</td>\n",
              "      <td>...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Human: You will extract information from the f...</td>\n",
              "      <td>Human: You will extract information from the f...</td>\n",
              "      <td>{'score_type': 'KL', 'gap_score': -0.106064621...</td>\n",
              "      <td>-0.106065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>3927efbf-3735-4c93-96fc-2782deec5e9e:1</td>\n",
              "      <td>Extraction</td>\n",
              "      <td>Model A had incorrect formatting of the CSV ta...</td>\n",
              "      <td>[{'content': 'You will extract information fro...</td>\n",
              "      <td>[False, False, False, True, False, False, Fals...</td>\n",
              "      <td>[{'content': 'You will extract information fro...</td>\n",
              "      <td>[{'content': 'You will extract information fro...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>grok-0701-2.research-models</td>\n",
              "      <td>grok-0805-1.research-models</td>\n",
              "      <td>...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Human: You will extract information from the f...</td>\n",
              "      <td>Human: You will extract information from the f...</td>\n",
              "      <td>{'score_type': 'KL', 'gap_score': -0.105023694...</td>\n",
              "      <td>-0.105024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340</th>\n",
              "      <td>6c56a226-dbf9-46f9-98ed-658813ea2d8f:4</td>\n",
              "      <td>Classification</td>\n",
              "      <td>Both models made errors in classifying the job...</td>\n",
              "      <td>[{'content': 'You are an intelligent assistant...</td>\n",
              "      <td>[False, False, False, False, False, False, Fal...</td>\n",
              "      <td>[{'content': 'You are an intelligent assistant...</td>\n",
              "      <td>[{'content': 'You are an intelligent assistant...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>grok-0701-2.research-models</td>\n",
              "      <td>grok-0805-1.research-models</td>\n",
              "      <td>...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Human: You are an intelligent assistant advisi...</td>\n",
              "      <td>Human: You are an intelligent assistant advisi...</td>\n",
              "      <td>{'score_type': 'KL', 'gap_score': -0.100402321...</td>\n",
              "      <td>-0.100402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>363</th>\n",
              "      <td>5be95b0c-e19d-4add-8557-a2f276394522:1</td>\n",
              "      <td>Classification</td>\n",
              "      <td>Both models followed the instructions verbatim...</td>\n",
              "      <td>[{'content': 'Analyse a series of blurbs about...</td>\n",
              "      <td>[False, False, False, True, False, False, Fals...</td>\n",
              "      <td>[{'content': 'Analyse a series of blurbs about...</td>\n",
              "      <td>[{'content': 'Analyse a series of blurbs about...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>grok-0701-2.research-models</td>\n",
              "      <td>grok-0805-1.research-models</td>\n",
              "      <td>...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Human: Analyse a series of blurbs about guitar...</td>\n",
              "      <td>Human: Analyse a series of blurbs about guitar...</td>\n",
              "      <td>{'score_type': 'KL', 'gap_score': -0.093293909...</td>\n",
              "      <td>-0.093294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>756</th>\n",
              "      <td>655a9956-a9c5-4dc5-a253-63dbd8d9d750:3</td>\n",
              "      <td>Other</td>\n",
              "      <td>Both of these responses would be appropriate g...</td>\n",
              "      <td>[{'content': 'You are a model that is designed...</td>\n",
              "      <td>[False, False, False, False, False, False, Fal...</td>\n",
              "      <td>[{'content': 'You are a model that is designed...</td>\n",
              "      <td>[{'content': 'You are a model that is designed...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>grok-0701-2.research-models</td>\n",
              "      <td>grok-0805-1.research-models</td>\n",
              "      <td>...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Human: You are a model that is designed to hel...</td>\n",
              "      <td>Human: You are a model that is designed to hel...</td>\n",
              "      <td>{'score_type': 'KL', 'gap_score': 0.0813806601...</td>\n",
              "      <td>0.081381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>b70550a3-fe2c-4ebe-b604-71192a2ff040:2</td>\n",
              "      <td>Other</td>\n",
              "      <td>Both models accurately calculated the smallest...</td>\n",
              "      <td>[{'content': 'Convert the input recipes to the...</td>\n",
              "      <td>[False, False, False, False, False, True, Fals...</td>\n",
              "      <td>[{'content': 'Convert the input recipes to the...</td>\n",
              "      <td>[{'content': 'Convert the input recipes to the...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>grok-0701-2.research-models</td>\n",
              "      <td>grok-0805-1.research-models</td>\n",
              "      <td>...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Human: Convert the input recipes to their smal...</td>\n",
              "      <td>Human: Convert the input recipes to their smal...</td>\n",
              "      <td>{'score_type': 'KL', 'gap_score': 0.0828912649...</td>\n",
              "      <td>0.082891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>b70550a3-fe2c-4ebe-b604-71192a2ff040:2</td>\n",
              "      <td>Other</td>\n",
              "      <td>Both models accurately calculated the smallest...</td>\n",
              "      <td>[{'content': 'Convert the input recipes to the...</td>\n",
              "      <td>[False, False, False, False, False, True, Fals...</td>\n",
              "      <td>[{'content': 'Convert the input recipes to the...</td>\n",
              "      <td>[{'content': 'Convert the input recipes to the...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>grok-0701-2.research-models</td>\n",
              "      <td>grok-0805-1.research-models</td>\n",
              "      <td>...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Human: Convert the input recipes to their smal...</td>\n",
              "      <td>Human: Convert the input recipes to their smal...</td>\n",
              "      <td>{'score_type': 'KL', 'gap_score': 0.0852000482...</td>\n",
              "      <td>0.085200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>364</th>\n",
              "      <td>5be95b0c-e19d-4add-8557-a2f276394522:3</td>\n",
              "      <td>Classification</td>\n",
              "      <td>Both models responded with modified classifica...</td>\n",
              "      <td>[{'content': 'Analyse a series of blurbs about...</td>\n",
              "      <td>[False, False, False, False, False, False, Fal...</td>\n",
              "      <td>[{'content': 'Analyse a series of blurbs about...</td>\n",
              "      <td>[{'content': 'Analyse a series of blurbs about...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>grok-0701-2.research-models</td>\n",
              "      <td>grok-0805-1.research-models</td>\n",
              "      <td>...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Human: Analyse a series of blurbs about guitar...</td>\n",
              "      <td>Human: Analyse a series of blurbs about guitar...</td>\n",
              "      <td>{'score_type': 'KL', 'gap_score': 0.0911822683...</td>\n",
              "      <td>0.091182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>754</th>\n",
              "      <td>0d45a2b9-5de5-4d0d-8a31-2be88955a298:1</td>\n",
              "      <td>Classification</td>\n",
              "      <td>Both models followed the instructions given. E...</td>\n",
              "      <td>[{'content': 'I'm trying to figure out when I ...</td>\n",
              "      <td>[False, False, False, True, False, False, Fals...</td>\n",
              "      <td>[{'content': 'I'm trying to figure out when I ...</td>\n",
              "      <td>[{'content': 'I'm trying to figure out when I ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>grok-0701-2.research-models</td>\n",
              "      <td>grok-0805-1.research-models</td>\n",
              "      <td>...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Human: I'm trying to figure out when I can kee...</td>\n",
              "      <td>Human: I'm trying to figure out when I can kee...</td>\n",
              "      <td>{'score_type': 'KL', 'gap_score': 0.1026359613...</td>\n",
              "      <td>0.102636</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>762 rows × 23 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8SRNwIxGNXKh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}